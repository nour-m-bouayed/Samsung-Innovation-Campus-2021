{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"ex_0504_SVM_.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"JZLotp_s70k6"},"source":["## Coding Exercise #0504"]},{"cell_type":"markdown","metadata":{"id":"ZTBxLv1t70lB"},"source":["### 1. Classification with SVM:"]},{"cell_type":"code","metadata":{"id":"I-Otfmvf70lD"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","from sklearn.model_selection import train_test_split,GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn import metrics\n","from sklearn.datasets import load_iris\n","warnings.filterwarnings(action='ignore')                  # Turn off the warnings.\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x93aNXfB70lF"},"source":["#### 1.1. Read in data:"]},{"cell_type":"code","metadata":{"id":"m7x5nnaY70lG"},"source":["# Load data.\n","data = load_iris()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDahH2Vt70lH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628675306382,"user_tz":-60,"elapsed":350,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"d5781368-0e0d-462b-912e-ef77fae77959"},"source":["# Explanatory variables.\n","X = data['data']\n","columns = list(data['feature_names'])\n","print(columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K8L9FRBS70lI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628675315328,"user_tz":-60,"elapsed":447,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"34efbb89-3746-4f12-87cf-07e666915a5d"},"source":["# Response variable.\n","Y = data['target']\n","labels = list(data['target_names'])\n","print(labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['setosa', 'versicolor', 'virginica']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aG_jKj7j70lK"},"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tp_RmlQ8oXYK"},"source":["Support Vector Machines (SVMs) are a method that uses points in a transformed problem space that best separate classes into two groups. Classification for multiple classes is supported by a one-vs-all method. SVM also supports regression by modeling the function with a minimum amount of allowable error.\n","\n","Question 1 : Use SVC() to fit a support vector machine to iris data.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBPXSjfxpV9y","executionInfo":{"status":"ok","timestamp":1628675659032,"user_tz":-60,"elapsed":317,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"d8777919-6cfc-4c9d-c746-e627b6c588cf"},"source":["from sklearn import metrics\n","from sklearn.svm import SVC\n","\n","model=SVC()\n","model.fit(X_train,Y_train)\n","print(model)\n","# make predictions\n","Y_predict=model.predict(X_test)\n","\n","\n","# summarize the fit of the model\n","print(metrics.classification_report(Y_test, Y_predict))\n","print(metrics.confusion_matrix(Y_test, Y_predict))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        16\n","           1       1.00      0.94      0.97        17\n","           2       0.92      1.00      0.96        12\n","\n","    accuracy                           0.98        45\n","   macro avg       0.97      0.98      0.98        45\n","weighted avg       0.98      0.98      0.98        45\n","\n","[[16  0  0]\n"," [ 0 16  1]\n"," [ 0  0 12]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vshQO-xX70lL"},"source":["#### 1.2. SVM hyperparameter optimization (RBF kernel):\n","\n","The SVM algorithm is implemented in practice using a kernel.\n","\n","The learning of the hyperplane in linear SVM is done by transforming the problem using some linear algebra, which is out of the scope of this introduction to SVM.\n","\n","https://towardsdatascience.com/a-to-z-of-svm-machine-learning-for-everyone-902fdd8fe9a1\n","\n","\n","\n","## Tuning Hyperparameters\n","\n","\n","- Kernel, The main function of the kernel is to transform the given dataset input data into the required form. There are various types of functions such as linear, polynomial, and radial basis function (RBF). Polynomial and RBF are useful for non-linear hyperplane. Polynomial and RBF kernels compute the separation line in the higher dimension. In some of the applications, it is suggested to use a more complex kernel to separate the classes that are curved or nonlinear. \n","\n","- Gamma; A lower value of Gamma will loosely fit the training dataset, whereas a higher value of gamma will exactly fit the training dataset, which causes over-fitting. In other words, you can say a low value of gamma considers only nearby points in calculating the separation line, while the a value of gamma considers all the data points in the calculation of the separation line.\n"]},{"cell_type":"markdown","metadata":{"id":"gACYfgRkwoZC"},"source":["#Let's do some tuning !!! :) "]},{"cell_type":"markdown","metadata":{"id":"ZD8MezZ-xJH1"},"source":["\n","Question \n","\n","- \n","There are two parameters for an RBF kernel SVM namely C and gamma, \n","Read the documentation and use gridCV to find best gama and best C.\n","\n","\n","https://aneesha.medium.com/svm-parameter-tuning-in-scikit-learn-using-gridsearchcv-2413c02125a0"]},{"cell_type":"markdown","metadata":{"id":"9lNLLQ9i70lN"},"source":["C     : Penalty parameter. <br>\n","gamma : kernel parameter ($\\gamma$)."]},{"cell_type":"code","metadata":{"id":"zv6ppH_370lO"},"source":["C_grid = 0.02*np.arange(1,20)\n","gamma_grid = 0.02*np.arange(1,50)\n","parameters = {'C': C_grid, 'gamma' : gamma_grid}\n","gridCV =  GridSearchCV(SVC(kernel='rbf'), parameters, cv=5,n_jobs=-1)           \n","#your code goes here, you can use\"n_jobs = -1\" to \"use all the CPU cores\".\n","gridCV.fit(X_train, Y_train)\n","best_C = gridCV.best_params_['C']\n","best_gamma = gridCV.best_params_['gamma']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9JYJVCU70lP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628676545481,"user_tz":-60,"elapsed":397,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"595c2e5d-d5f2-4c6a-8c83-8bbfef571ea6"},"source":["print(\"SVM best C : \" + str(best_C))\n","print(\"SVM best gamma : \" + str(best_gamma))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM best C : 0.12\n","SVM best gamma : 0.86\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EY1ifhNWySok"},"source":["Now let's use best C and best gamma as parameters to our SVM model"]},{"cell_type":"code","metadata":{"id":"5CRkH0zI70lQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628676800492,"user_tz":-60,"elapsed":253,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"1596ac63-f30b-4704-d20d-490522b4c982"},"source":["SVM_best = SVC(C=best_C,gamma=best_gamma)\n","SVM_best.fit(X_train, Y_train);\n","Y_pred = SVM_best.predict(X_test)\n","print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM best accuracy : 0.978\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dHsqgFOUJ7Yx"},"source":["Questions:\n","\n","- Set C = 0.8 and gama to 0.2 and check the accuracy of your SVM and check the accuracy of your model.\n","- Set C = 0.02 and gama to 0.2 and check the accuracy of your SVM.\n","\n","What will happen if C is to small or to big?"]},{"cell_type":"code","metadata":{"id":"HvCLe_ykLYmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628676941032,"user_tz":-60,"elapsed":253,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"8f505ff9-ca2e-485e-fd81-fa72f5b44d20"},"source":["SVM_1 = SVC(C=0.8,gamma=0.2)\n","SVM_1.fit(X_train, Y_train);\n","Y_pred = SVM_1.predict(X_test)\n","print( \"SVM accuracy with C=0.8 and gamma=0.2 : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM accuracy with C=0.8 and gamma=0.2 : 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p6OH6l8rLYaN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628676938696,"user_tz":-60,"elapsed":306,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"58d10870-20fe-4ded-ed00-0a3ca8fdf107"},"source":["SVM_2 = SVC(C=0.8,gamma=0.2)\n","SVM_2.fit(X_train, Y_train);\n","Y_pred = SVM_2.predict(X_test)\n","print( \"SVM accuracy with C=0.02 and gamma=0.2 : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM accuracy with C=0.02 and gamma=0.2 : 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"56IRQORCLYOG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Byywb_Ftf5k"},"source":["We get an accuracy of 1"]},{"cell_type":"markdown","metadata":{"id":"aFC_5bD170lQ"},"source":["#### 1.3. SVM hyperparameter optimization (Polynomial kernel):\n","Now let's do the same steps but with the polynomial kernel,  use gridCV to find best gama and best C in a polynomial kernel."]},{"cell_type":"code","metadata":{"id":"IcX4TUWN70lS"},"source":["C_grid = 0.02*np.arange(1,20)\n","gamma_grid = 0.02*np.arange(1,50)\n","parameters = {'C': C_grid, 'gamma' : gamma_grid}\n","gridCV =  GridSearchCV(SVC(kernel='poly'), parameters, cv=5,n_jobs=-1)           \n","#your code goes here, you can use\"n_jobs = -1\" to \"use all the CPU cores\".\n","gridCV.fit(X_train, Y_train)\n","best_C = gridCV.best_params_['C']\n","best_gamma = gridCV.best_params_['gamma']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rUKMEaf70lT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628677175908,"user_tz":-60,"elapsed":262,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"9f65ae5b-15a5-4001-b111-9086b5d77c2d"},"source":["print(\"SVM best C : \" + str(best_C))\n","print(\"SVM best gamma : \" + str(best_gamma))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM best C : 0.04\n","SVM best gamma : 0.06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zXJ6BsOI70lU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628677179470,"user_tz":-60,"elapsed":250,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"","userId":"12911441041777911065"}},"outputId":"a55d40ca-9dad-4d13-eec2-006cbad5040e"},"source":["SVM_best = SVC(kernel='poly', C=best_C,gamma=best_gamma)\n","SVM_best.fit(X_train, Y_train);\n","Y_pred = SVM_best.predict(X_test)\n","print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM best accuracy : 0.956\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mY9XHe5u70lU"},"source":[""],"execution_count":null,"outputs":[]}]}