{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"authorship_tag":"ABX9TyNFNRswOOHzRKA62LIYJHs4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5gRgqi4tvjO5","executionInfo":{"status":"ok","timestamp":1632128181166,"user_tz":-60,"elapsed":23044,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"7542b2ed-6098-4d76-d21b-7b75abffd8af"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbq8oAasuuhV","executionInfo":{"status":"ok","timestamp":1632128210433,"user_tz":-60,"elapsed":25585,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"31fa1c90-d274-4043-e90a-57113c4fa562"},"source":["!git clone https://github.com/tensorflow/models.git\n","%cd /content/models/research/\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 62958, done.\u001b[K\n","remote: Counting objects: 100% (356/356), done.\u001b[K\n","remote: Compressing objects: 100% (126/126), done.\u001b[K\n","remote: Total 62958 (delta 231), reused 350 (delta 230), pack-reused 62602\u001b[K\n","Receiving objects: 100% (62958/62958), 574.60 MiB | 31.01 MiB/s, done.\n","Resolving deltas: 100% (43921/43921), done.\n","/content/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"pMXixDTKuH0-","executionInfo":{"status":"ok","timestamp":1632128215806,"user_tz":-60,"elapsed":3170,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}}},"source":["import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from google.colab.patches import cv2_imshow\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","\n","PATH_TO_SAVED_MODEL = \"/content/gdrive/MyDrive/plantdoc/PlantDoc-Dataset/exported_model/saved_model\"\n","PATH_TO_LABELS = \"/content/gdrive/My Drive/data_tfrecord/PlantDoc.v1-resize-416x416.tfrecord/train/leaves_label_map.pbtxt\"\n","IMAGE_PATH = \"/content/gdrive/MyDrive/plantdoc/PlantDoc-Dataset/train/Apple Scab Leaf/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG\"\n","\n","\n","def object_model_predict(img_path,PATH_TO_SAVED_MODEL,PATH_TO_LABELS):\n","    detect_fn = tf.compat.v2.saved_model.load(str(PATH_TO_SAVED_MODEL),None)\n","    category_index = label_map_util.create_category_index_from_labelmap(str(PATH_TO_LABELS),use_display_name=True)\n","    image_np = plt.imread(img_path)\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","\n","    # input_tensor = np.expand_dims(image_np, 0)\n","    detections = detect_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                   for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.5,\n","          agnostic_mode=False)  \n","    \n","    return image_np_with_detections"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"k6WhB0MYuyet","executionInfo":{"status":"error","timestamp":1632128480719,"user_tz":-60,"elapsed":777,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"9413f345-2b49-492f-8524-461b040ee2fc"},"source":["if __name__ == '__main__':\n","  image = object_model_predict(IMAGE_PATH,PATH_TO_SAVED_MODEL,PATH_TO_LABELS)\n","  cv2_imshow(image)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0584460372a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_model_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATH_TO_SAVED_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-401f2caba526>\u001b[0m in \u001b[0;36mobject_model_predict\u001b[0;34m(img_path, PATH_TO_SAVED_MODEL, PATH_TO_LABELS)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobject_model_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATH_TO_SAVED_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdetect_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_SAVED_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcategory_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_category_index_from_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    862\u001b[0m   \"\"\"\n\u001b[1;32m    863\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementReadApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOAD_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 878\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   debug_info_path = os.path.join(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 121\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/gdrive/MyDrive/plantdoc/PlantDoc-Dataset/exported_model/saved_model/{saved_model.pbtxt|saved_model.pb}"]}]}]}