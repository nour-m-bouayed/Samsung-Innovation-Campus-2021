{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Classification_PlantifyDr_train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CKO8VUH4bZDl"},"source":["Uploaded Kaggle.json"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOarYTfCaAK6","executionInfo":{"status":"ok","timestamp":1633508443506,"user_tz":-60,"elapsed":42651,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"b010ce45-051a-432f-e87c-87f29628a07e"},"source":["! pip install -q kaggle\n","! mkdir ~/.kaggle\n","%cd /content\n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download lavaman151/plantifydr-dataset"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n","/content\n","Downloading plantifydr-dataset.zip to /content\n","100% 2.58G/2.58G [00:33<00:00, 35.3MB/s]\n","\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0l_HfdepCiNg","executionInfo":{"status":"ok","timestamp":1648211196005,"user_tz":-60,"elapsed":41628,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"46176dd5-b3ca-4053-ecaa-603cf4ac9946"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"zk6QIv_lbngO"},"source":["import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from glob import glob\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from tensorflow import keras\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense,Flatten,GlobalAveragePooling2D, Conv2D,InputLayer\n","from tensorflow.keras.layers import BatchNormalization,Dropout\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.applications.mobilenet import MobileNet\n","from tensorflow.keras.applications import InceptionResNetV2\n","import keras.backend as K\n","from tensorflow.keras.applications import MobileNetV2\n","\n","from tensorflow import keras\n","\n","from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swqc5m2dbs8H"},"source":["TRAINING_DATA_PATH = \"/content/drive/MyDrive/HAICK/challenge3\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8Cze9S8bw4W"},"source":["IMAGE_SIZE = 256\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.009\n","MOMENTUM = 0.9 \n","EPOCHS = 20\n","PATIENCE = 30\n","#CLASSES = len(glob('data/train'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TX_9AkAmcwvy"},"source":["The following model is basically a MobileNet model that has been pretrained on PlantVillage Data (https://www.kaggle.com/thunder2901/leaf-disease-classification-mobilenet/data )"]},{"cell_type":"code","metadata":{"id":"D1LkH7VCb1cI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648211020216,"user_tz":-60,"elapsed":5448,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"9b3cc5fa-c3e0-4d00-c99d-ea2ebd8bff54"},"source":["base_model = keras.applications.MobileNet(weights=\"imagenet\",include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n","17227776/17225924 [==============================] - 1s 0us/step\n","17235968/17225924 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IY1mKKgXb3xx","executionInfo":{"elapsed":1375,"status":"ok","timestamp":1648211687062,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"},"user_tz":-60},"outputId":"277306c0-b012-4576-c015-58b84da54b34"},"source":["base_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"mobilenet_1.00_224\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," conv1 (Conv2D)              multiple                  864       \n","                                                                 \n"," conv1_bn (BatchNormalizatio  multiple                 128       \n"," n)                                                              \n","                                                                 \n"," conv1_relu (ReLU)           (None, 128, 128, 32)      0         \n","                                                                 \n"," conv_dw_1 (DepthwiseConv2D)  (None, 128, 128, 32)     288       \n","                                                                 \n"," conv_dw_1_bn (BatchNormaliz  (None, 128, 128, 32)     128       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_1_relu (ReLU)       (None, 128, 128, 32)      0         \n","                                                                 \n"," conv_pw_1 (Conv2D)          (None, 128, 128, 64)      2048      \n","                                                                 \n"," conv_pw_1_bn (BatchNormaliz  (None, 128, 128, 64)     256       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_1_relu (ReLU)       (None, 128, 128, 64)      0         \n","                                                                 \n"," conv_pad_2 (ZeroPadding2D)  (None, 129, 129, 64)      0         \n","                                                                 \n"," conv_dw_2 (DepthwiseConv2D)  (None, 64, 64, 64)       576       \n","                                                                 \n"," conv_dw_2_bn (BatchNormaliz  (None, 64, 64, 64)       256       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_2_relu (ReLU)       (None, 64, 64, 64)        0         \n","                                                                 \n"," conv_pw_2 (Conv2D)          (None, 64, 64, 128)       8192      \n","                                                                 \n"," conv_pw_2_bn (BatchNormaliz  (None, 64, 64, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_2_relu (ReLU)       (None, 64, 64, 128)       0         \n","                                                                 \n"," conv_dw_3 (DepthwiseConv2D)  (None, 64, 64, 128)      1152      \n","                                                                 \n"," conv_dw_3_bn (BatchNormaliz  (None, 64, 64, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_3_relu (ReLU)       (None, 64, 64, 128)       0         \n","                                                                 \n"," conv_pw_3 (Conv2D)          (None, 64, 64, 128)       16384     \n","                                                                 \n"," conv_pw_3_bn (BatchNormaliz  (None, 64, 64, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_pw_3_relu (ReLU)       (None, 64, 64, 128)       0         \n","                                                                 \n"," conv_pad_4 (ZeroPadding2D)  (None, 65, 65, 128)       0         \n","                                                                 \n"," conv_dw_4 (DepthwiseConv2D)  (None, 32, 32, 128)      1152      \n","                                                                 \n"," conv_dw_4_bn (BatchNormaliz  (None, 32, 32, 128)      512       \n"," ation)                                                          \n","                                                                 \n"," conv_dw_4_relu (ReLU)       (None, 32, 32, 128)       0         \n","                                                                 \n"," conv_pw_4 (Conv2D)          (None, 32, 32, 256)       32768     \n","                                                                 \n"," conv_pw_4_bn (BatchNormaliz  (None, 32, 32, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_4_relu (ReLU)       (None, 32, 32, 256)       0         \n","                                                                 \n"," conv_dw_5 (DepthwiseConv2D)  (None, 32, 32, 256)      2304      \n","                                                                 \n"," conv_dw_5_bn (BatchNormaliz  (None, 32, 32, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_5_relu (ReLU)       (None, 32, 32, 256)       0         \n","                                                                 \n"," conv_pw_5 (Conv2D)          (None, 32, 32, 256)       65536     \n","                                                                 \n"," conv_pw_5_bn (BatchNormaliz  (None, 32, 32, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_5_relu (ReLU)       (None, 32, 32, 256)       0         \n","                                                                 \n"," conv_pad_6 (ZeroPadding2D)  (None, 33, 33, 256)       0         \n","                                                                 \n"," conv_dw_6 (DepthwiseConv2D)  (None, 16, 16, 256)      2304      \n","                                                                 \n"," conv_dw_6_bn (BatchNormaliz  (None, 16, 16, 256)      1024      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_6_relu (ReLU)       (None, 16, 16, 256)       0         \n","                                                                 \n"," conv_pw_6 (Conv2D)          (None, 16, 16, 512)       131072    \n","                                                                 \n"," conv_pw_6_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_6_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_dw_7 (DepthwiseConv2D)  (None, 16, 16, 512)      4608      \n","                                                                 \n"," conv_dw_7_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_7_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_pw_7 (Conv2D)          (None, 16, 16, 512)       262144    \n","                                                                 \n"," conv_pw_7_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_7_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_dw_8 (DepthwiseConv2D)  (None, 16, 16, 512)      4608      \n","                                                                 \n"," conv_dw_8_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_8_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_pw_8 (Conv2D)          (None, 16, 16, 512)       262144    \n","                                                                 \n"," conv_pw_8_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_8_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_dw_9 (DepthwiseConv2D)  (None, 16, 16, 512)      4608      \n","                                                                 \n"," conv_dw_9_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_dw_9_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_pw_9 (Conv2D)          (None, 16, 16, 512)       262144    \n","                                                                 \n"," conv_pw_9_bn (BatchNormaliz  (None, 16, 16, 512)      2048      \n"," ation)                                                          \n","                                                                 \n"," conv_pw_9_relu (ReLU)       (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_dw_10 (DepthwiseConv2D  (None, 16, 16, 512)      4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_10_bn (BatchNormali  (None, 16, 16, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_10_relu (ReLU)      (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_pw_10 (Conv2D)         (None, 16, 16, 512)       262144    \n","                                                                 \n"," conv_pw_10_bn (BatchNormali  (None, 16, 16, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_10_relu (ReLU)      (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_dw_11 (DepthwiseConv2D  (None, 16, 16, 512)      4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_11_bn (BatchNormali  (None, 16, 16, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_11_relu (ReLU)      (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_pw_11 (Conv2D)         (None, 16, 16, 512)       262144    \n","                                                                 \n"," conv_pw_11_bn (BatchNormali  (None, 16, 16, 512)      2048      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_11_relu (ReLU)      (None, 16, 16, 512)       0         \n","                                                                 \n"," conv_pad_12 (ZeroPadding2D)  (None, 17, 17, 512)      0         \n","                                                                 \n"," conv_dw_12 (DepthwiseConv2D  (None, 8, 8, 512)        4608      \n"," )                                                               \n","                                                                 \n"," conv_dw_12_bn (BatchNormali  (None, 8, 8, 512)        2048      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_12_relu (ReLU)      (None, 8, 8, 512)         0         \n","                                                                 \n"," conv_pw_12 (Conv2D)         (None, 8, 8, 1024)        524288    \n","                                                                 \n"," conv_pw_12_bn (BatchNormali  (None, 8, 8, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_12_relu (ReLU)      (None, 8, 8, 1024)        0         \n","                                                                 \n"," conv_dw_13 (DepthwiseConv2D  (None, 8, 8, 1024)       9216      \n"," )                                                               \n","                                                                 \n"," conv_dw_13_bn (BatchNormali  (None, 8, 8, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_dw_13_relu (ReLU)      (None, 8, 8, 1024)        0         \n","                                                                 \n"," conv_pw_13 (Conv2D)         (None, 8, 8, 1024)        1048576   \n","                                                                 \n"," conv_pw_13_bn (BatchNormali  (None, 8, 8, 1024)       4096      \n"," zation)                                                         \n","                                                                 \n"," conv_pw_13_relu (ReLU)      (None, 8, 8, 1024)        0         \n","                                                                 \n","=================================================================\n","Total params: 3,228,864\n","Trainable params: 3,206,976\n","Non-trainable params: 21,888\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkMGYtqNcAAz","executionInfo":{"elapsed":406,"status":"ok","timestamp":1648211873970,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"},"user_tz":-60},"outputId":"239450b8-8a95-458f-8922-9affbfa3f45c"},"source":["train_datagen = ImageDataGenerator(rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2) # set validation split\n","\n","train = train_datagen.flow_from_directory(\n","    TRAINING_DATA_PATH,\n","    target_size=(256,256),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training') # set as training data\n","\n","valid = train_datagen.flow_from_directory(\n","    TRAINING_DATA_PATH, # same directory as training data\n","    target_size=(256,256),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='validation') # set as validation data\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1395 images belonging to 3 classes.\n","Found 348 images belonging to 3 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"YKeU_EC3q4m-"},"source":["inputShape = (256, 256, 3)\n","model=Sequential()\n","\n","model.add(InputLayer(input_shape=inputShape))\n","  \n","model.add(Dense(1024, activation='relu',name='fc1'))\n","model.add(Dropout(0.5,name='Dropout_1'))\n","model.add(BatchNormalization())\n","model.add(Dense(512, activation='relu',name='fc2'))\n","model.add(Dropout(0.3,name = 'Dropout'))\n","model.add(Dense(3,activation = 'softmax',name='output'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GchRN8t_EXZ2","executionInfo":{"status":"ok","timestamp":1648211919983,"user_tz":-60,"elapsed":966,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"db1e804b-fb2e-4ab4-9bb3-403911c6e74d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," fc1 (Dense)                 (None, 256, 256, 1024)    4096      \n","                                                                 \n"," Dropout_1 (Dropout)         (None, 256, 256, 1024)    0         \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 256, 256, 1024)   4096      \n"," hNormalization)                                                 \n","                                                                 \n"," fc2 (Dense)                 (None, 256, 256, 512)     524800    \n","                                                                 \n"," Dropout (Dropout)           (None, 256, 256, 512)     0         \n","                                                                 \n"," output (Dense)              (None, 256, 256, 1)       513       \n","                                                                 \n","=================================================================\n","Total params: 533,505\n","Trainable params: 531,457\n","Non-trainable params: 2,048\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"IniZ-Mh3rROS"},"source":["adam=optimizers.Adam(learning_rate=0.001)\n","model.compile(\n","        loss = 'categorical_crossentropy',\n","        optimizer = adam,\n","        metrics = ['accuracy']\n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"id":"SGRLfepjFmyk","executionInfo":{"status":"ok","timestamp":1648211960211,"user_tz":-60,"elapsed":26,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}},"outputId":"3142d73f-7341-47f6-fbc1-61a2db5bae16","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.preprocessing.image.DirectoryIterator at 0x7f594c40b210>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":817},"id":"_oXUu7rbciQg","outputId":"d23faca3-131f-407f-9b89-9d7c0804ad27","executionInfo":{"status":"error","timestamp":1648211934196,"user_tz":-60,"elapsed":9017,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"}}},"source":["model.fit_generator(\n","    train,\n","    steps_per_epoch = train.samples // BATCH_SIZE,\n","    validation_data = valid, \n","    validation_steps = valid.samples // BATCH_SIZE,\n","    epochs = 10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-fe706b820884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     epochs = 10)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1790, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, None) and (None, 256, 256, 1) are incompatible\n"]}]},{"cell_type":"code","metadata":{"id":"ZAWQLhKf9JDM"},"source":["y_pred=model.predict(valid)\n","y_pred=np.argmax(y_pred,axis=1)\n","y_true=valid.classes\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBn8nbXt_jSF","executionInfo":{"elapsed":513,"status":"ok","timestamp":1633111443509,"user":{"displayName":"NOUR MERIEM BOUAYED","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12911441041777911065"},"user_tz":-60},"outputId":"549ed26d-e064-4953-ab40-f73f7a34ee43"},"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_true,y_pred)"],"execution_count":null,"outputs":[{"data":{"text/plain":["0.11356013416387159"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]}]}